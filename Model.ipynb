{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import collections\n",
    "import tensorflow as tf \n",
    "import re\n",
    "import h5py\n",
    "import argparse\n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD PREPROCESSED TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load necessary files: Here we have loaded file for training\n",
    "df_final = pickle.load(open('train_df_final.pkl', 'rb'))\n",
    "features = pickle.load(open('image_feature_train.pkl', 'rb'))\n",
    "word_to_idx = pickle.load(open('word_to_idx.pkl', 'rb'))\n",
    "idx_to_word = pickle.load(open('idx_to_word.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Activation, Embedding, merge, LSTM, Dropout, Dense, RepeatVector, BatchNormalization, \\\n",
    "    TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "from numpy.random import seed\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "Compiling model...\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "PADDING_LEN = 17\n",
    "vocabulary_size=len(word_to_idx)\n",
    "embed_size=150\n",
    "question_max_len=PADDING_LEN-1\n",
    "answer_max_len=PADDING_LEN-1\n",
    "# Image\n",
    "k_image_input = Input(shape=(4096,))\n",
    "k_image_repeat = RepeatVector(n=question_max_len)(k_image_input)\n",
    "\n",
    "# Question\n",
    "k_question_input = Input(shape=(question_max_len,), dtype='int32')\n",
    "k_question_embedded = Embedding(input_dim=vocabulary_size, output_dim=embed_size, input_length=question_max_len)(k_question_input)  \n",
    "k_question_embedded = Dropout(0.3)(k_question_embedded)\n",
    "\n",
    "# Merge\n",
    "k_merged = concatenate([k_image_repeat, k_question_embedded])  # Merge for layers merge for tensors\n",
    "k_merged = BatchNormalization()(k_merged)\n",
    "\n",
    "#Set encoder\n",
    "k_encoder_outputs, k_state_h, k_state_c  = LSTM(embed_size, return_state=True)(k_merged)\n",
    "k_encoder_outputs = Dropout(0.3)(k_encoder_outputs)\n",
    "k_encoder_states = [k_state_h, k_state_c]\n",
    "embed_size\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "k_decoder_inputs = Input(shape=(None, vocabulary_size))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "k_decoder_lstm = LSTM(embed_size, return_sequences=True, return_state=True)\n",
    "k_decoder_outputs, _, _ = k_decoder_lstm(k_decoder_inputs, initial_state=k_encoder_states)\n",
    "\n",
    "#Final Layer\n",
    "k_decoder_dense = Dense(vocabulary_size, activation='softmax')\n",
    "k_decoder_outputs = k_decoder_dense(k_decoder_outputs)\n",
    "\n",
    "model = Model([k_image_input, k_question_input, k_decoder_inputs], k_decoder_outputs)\n",
    "print('Model created')\n",
    "print('Compiling model...')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "print('Model compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input=np.array(features)\n",
    "question_inputs=np.array(df_final['Q_Encoded'])\n",
    "question_inputs=np.array([np.array(item) for item in question_inputs])\n",
    "decoder_inputs =np.array(df_final['A_Encoded'])\n",
    "decoder_targets =np.array(df_final['A_Encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_question_input_data = np.zeros(\n",
    "    (len(question_inputs), PADDING_LEN-1, vocabulary_size),\n",
    "    dtype='float32')\n",
    "m_decoder_inputs = np.zeros(\n",
    "    (len(decoder_inputs), PADDING_LEN-1, vocabulary_size),\n",
    "    dtype='float32')\n",
    "m_decoder_targets= np.zeros(\n",
    "    (len(decoder_targets), PADDING_LEN-1, vocabulary_size),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(question_inputs, decoder_inputs)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        m_question_input_data[i, t, char] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        m_decoder_inputs[i, t, char] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            m_decoder_targets[i, t - 1, char] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1933, 16, 1283)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_inputs=np.array([np.array(item) for item in question_inputs])\n",
    "m_decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1546 samples, validate on 387 samples\n",
      "Epoch 1/400\n",
      "1546/1546 [==============================] - 13s 8ms/step - loss: 2.7002 - acc: 0.7851 - val_loss: 0.9653 - val_acc: 0.8324\n",
      "Epoch 2/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.7426 - acc: 0.8444 - val_loss: 0.8752 - val_acc: 0.8324\n",
      "Epoch 3/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.6534 - acc: 0.8663 - val_loss: 0.8161 - val_acc: 0.8792\n",
      "Epoch 4/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 0.6056 - acc: 0.8851 - val_loss: 0.8096 - val_acc: 0.8784\n",
      "Epoch 5/400\n",
      "1546/1546 [==============================] - 1s 771us/step - loss: 0.5705 - acc: 0.9011 - val_loss: 0.7746 - val_acc: 0.8911\n",
      "Epoch 6/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 0.5330 - acc: 0.9113 - val_loss: 0.7725 - val_acc: 0.8782\n",
      "Epoch 7/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.4957 - acc: 0.9122 - val_loss: 0.8099 - val_acc: 0.8931\n",
      "Epoch 8/400\n",
      "1546/1546 [==============================] - 1s 797us/step - loss: 0.4647 - acc: 0.9148 - val_loss: 0.7302 - val_acc: 0.8920\n",
      "Epoch 9/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 0.4361 - acc: 0.9172 - val_loss: 0.7089 - val_acc: 0.8957\n",
      "Epoch 10/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.4154 - acc: 0.9186 - val_loss: 0.7643 - val_acc: 0.8965\n",
      "Epoch 11/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 0.3900 - acc: 0.9215 - val_loss: 0.7385 - val_acc: 0.8983\n",
      "Epoch 12/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 0.3807 - acc: 0.9232 - val_loss: 0.7629 - val_acc: 0.8987\n",
      "Epoch 13/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 0.3646 - acc: 0.9268 - val_loss: 0.7603 - val_acc: 0.8999\n",
      "Epoch 14/400\n",
      "1546/1546 [==============================] - 1s 795us/step - loss: 0.3478 - acc: 0.9300 - val_loss: 0.7591 - val_acc: 0.8965\n",
      "Epoch 15/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.3447 - acc: 0.9303 - val_loss: 0.7433 - val_acc: 0.8999\n",
      "Epoch 16/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 0.3239 - acc: 0.9348 - val_loss: 0.7570 - val_acc: 0.8991\n",
      "Epoch 17/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 0.3229 - acc: 0.9354 - val_loss: 0.7464 - val_acc: 0.9015\n",
      "Epoch 18/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.3005 - acc: 0.9393 - val_loss: 0.7420 - val_acc: 0.9020\n",
      "Epoch 19/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 0.2905 - acc: 0.9408 - val_loss: 0.8628 - val_acc: 0.8989\n",
      "Epoch 20/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 0.2800 - acc: 0.9426 - val_loss: 0.7889 - val_acc: 0.9020\n",
      "Epoch 21/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 0.2689 - acc: 0.9434 - val_loss: 0.7724 - val_acc: 0.9033\n",
      "Epoch 22/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.2612 - acc: 0.9447 - val_loss: 0.8057 - val_acc: 0.9020\n",
      "Epoch 23/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.2469 - acc: 0.9471 - val_loss: 0.8164 - val_acc: 0.9028\n",
      "Epoch 24/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 0.2362 - acc: 0.9490 - val_loss: 0.7608 - val_acc: 0.9047\n",
      "Epoch 25/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 0.2284 - acc: 0.9502 - val_loss: 0.7887 - val_acc: 0.9005\n",
      "Epoch 26/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 0.2179 - acc: 0.9518 - val_loss: 0.7943 - val_acc: 0.9029\n",
      "Epoch 27/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.2093 - acc: 0.9536 - val_loss: 0.8034 - val_acc: 0.9034\n",
      "Epoch 28/400\n",
      "1546/1546 [==============================] - 1s 796us/step - loss: 0.1974 - acc: 0.9557 - val_loss: 0.8303 - val_acc: 0.9002\n",
      "Epoch 29/400\n",
      "1546/1546 [==============================] - 1s 837us/step - loss: 0.1898 - acc: 0.9569 - val_loss: 0.7746 - val_acc: 0.9039\n",
      "Epoch 30/400\n",
      "1546/1546 [==============================] - 1s 793us/step - loss: 0.1801 - acc: 0.9594 - val_loss: 0.8244 - val_acc: 0.9023\n",
      "Epoch 31/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 0.1712 - acc: 0.9615 - val_loss: 0.8070 - val_acc: 0.9021\n",
      "Epoch 32/400\n",
      "1546/1546 [==============================] - 1s 771us/step - loss: 0.1636 - acc: 0.9632 - val_loss: 0.8220 - val_acc: 0.9028\n",
      "Epoch 33/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 0.1556 - acc: 0.9642 - val_loss: 0.8044 - val_acc: 0.9010\n",
      "Epoch 34/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.1456 - acc: 0.9674 - val_loss: 0.8342 - val_acc: 0.8999\n",
      "Epoch 35/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 0.1387 - acc: 0.9690 - val_loss: 0.8433 - val_acc: 0.9013\n",
      "Epoch 36/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 0.1316 - acc: 0.9710 - val_loss: 0.8083 - val_acc: 0.9012\n",
      "Epoch 37/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 0.1234 - acc: 0.9738 - val_loss: 0.8324 - val_acc: 0.9007\n",
      "Epoch 38/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 0.1154 - acc: 0.9749 - val_loss: 0.8589 - val_acc: 0.9004\n",
      "Epoch 39/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.1084 - acc: 0.9773 - val_loss: 0.8527 - val_acc: 0.8971\n",
      "Epoch 40/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.1020 - acc: 0.9793 - val_loss: 0.8638 - val_acc: 0.9023\n",
      "Epoch 41/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0962 - acc: 0.9811 - val_loss: 0.8666 - val_acc: 0.9018\n",
      "Epoch 42/400\n",
      "1546/1546 [==============================] - 1s 768us/step - loss: 0.0900 - acc: 0.9831 - val_loss: 0.8796 - val_acc: 0.9000\n",
      "Epoch 43/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.0847 - acc: 0.9844 - val_loss: 0.8586 - val_acc: 0.9007\n",
      "Epoch 44/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0782 - acc: 0.9867 - val_loss: 0.8644 - val_acc: 0.8994\n",
      "Epoch 45/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.0711 - acc: 0.9885 - val_loss: 0.8799 - val_acc: 0.9004\n",
      "Epoch 46/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.0657 - acc: 0.9901 - val_loss: 0.8741 - val_acc: 0.9005\n",
      "Epoch 47/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0606 - acc: 0.9911 - val_loss: 0.8803 - val_acc: 0.9010\n",
      "Epoch 48/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0589 - acc: 0.9919 - val_loss: 0.8799 - val_acc: 0.9010\n",
      "Epoch 49/400\n",
      "1546/1546 [==============================] - 1s 770us/step - loss: 0.0523 - acc: 0.9935 - val_loss: 0.8889 - val_acc: 0.9004\n",
      "Epoch 50/400\n",
      "1546/1546 [==============================] - 1s 768us/step - loss: 0.0489 - acc: 0.9942 - val_loss: 0.8981 - val_acc: 0.9025\n",
      "Epoch 51/400\n",
      "1546/1546 [==============================] - 1s 767us/step - loss: 0.0449 - acc: 0.9949 - val_loss: 0.8787 - val_acc: 0.9005\n",
      "Epoch 52/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.0442 - acc: 0.9943 - val_loss: 0.8789 - val_acc: 0.9010\n",
      "Epoch 53/400\n",
      "1546/1546 [==============================] - 1s 771us/step - loss: 0.0374 - acc: 0.9964 - val_loss: 0.8804 - val_acc: 0.9020\n",
      "Epoch 54/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 0.0374 - acc: 0.9957 - val_loss: 0.8720 - val_acc: 0.8994\n",
      "Epoch 55/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0325 - acc: 0.9968 - val_loss: 0.9066 - val_acc: 0.9025\n",
      "Epoch 56/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 0.0299 - acc: 0.9969 - val_loss: 0.8983 - val_acc: 0.8999\n",
      "Epoch 57/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 0.0267 - acc: 0.9983 - val_loss: 0.8937 - val_acc: 0.9025\n",
      "Epoch 58/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 0.0265 - acc: 0.9975 - val_loss: 0.9078 - val_acc: 0.9008\n",
      "Epoch 59/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 0.0239 - acc: 0.9979 - val_loss: 0.9058 - val_acc: 0.9033\n",
      "Epoch 60/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 0.0212 - acc: 0.9983 - val_loss: 0.9055 - val_acc: 0.9031\n",
      "Epoch 61/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 0.0197 - acc: 0.9985 - val_loss: 0.9046 - val_acc: 0.9021\n",
      "Epoch 62/400\n",
      "1546/1546 [==============================] - 1s 794us/step - loss: 0.0195 - acc: 0.9980 - val_loss: 0.9060 - val_acc: 0.9028\n",
      "Epoch 63/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.0168 - acc: 0.9987 - val_loss: 0.8959 - val_acc: 0.9031\n",
      "Epoch 64/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0153 - acc: 0.9987 - val_loss: 0.9234 - val_acc: 0.9029\n",
      "Epoch 65/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.0143 - acc: 0.9989 - val_loss: 0.9183 - val_acc: 0.9020\n",
      "Epoch 66/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 0.0145 - acc: 0.9985 - val_loss: 0.9035 - val_acc: 0.9031\n",
      "Epoch 67/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0132 - acc: 0.9986 - val_loss: 0.9115 - val_acc: 0.9026\n",
      "Epoch 68/400\n",
      "1546/1546 [==============================] - 1s 795us/step - loss: 0.0111 - acc: 0.9992 - val_loss: 0.9111 - val_acc: 0.9020\n",
      "Epoch 69/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0113 - acc: 0.9991 - val_loss: 0.9162 - val_acc: 0.9037\n",
      "Epoch 70/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0101 - acc: 0.9991 - val_loss: 0.9241 - val_acc: 0.9029\n",
      "Epoch 71/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 0.0080 - acc: 0.9995 - val_loss: 0.9199 - val_acc: 0.9015\n",
      "Epoch 72/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.9298 - val_acc: 0.9028\n",
      "Epoch 73/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0088 - acc: 0.9989 - val_loss: 0.9383 - val_acc: 0.9037\n",
      "Epoch 74/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0087 - acc: 0.9987 - val_loss: 0.9222 - val_acc: 0.9049\n",
      "Epoch 75/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.0065 - acc: 0.9992 - val_loss: 0.9158 - val_acc: 0.9050\n",
      "Epoch 76/400\n",
      "1546/1546 [==============================] - 1s 768us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.9287 - val_acc: 0.9060\n",
      "Epoch 77/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.9369 - val_acc: 0.9052\n",
      "Epoch 78/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.0056 - acc: 0.9994 - val_loss: 0.9375 - val_acc: 0.9060\n",
      "Epoch 79/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 0.0044 - acc: 0.9997 - val_loss: 0.9345 - val_acc: 0.9026\n",
      "Epoch 80/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 0.0066 - acc: 0.9993 - val_loss: 0.9351 - val_acc: 0.9050\n",
      "Epoch 81/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.9233 - val_acc: 0.9041\n",
      "Epoch 82/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 0.0061 - acc: 0.9989 - val_loss: 0.9252 - val_acc: 0.9050\n",
      "Epoch 83/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.9333 - val_acc: 0.9029\n",
      "Epoch 84/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.9444 - val_acc: 0.9034\n",
      "Epoch 85/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.9406 - val_acc: 0.9044\n",
      "Epoch 86/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 0.0036 - acc: 0.9995 - val_loss: 0.9487 - val_acc: 0.9033\n",
      "Epoch 87/400\n",
      "1546/1546 [==============================] - 1s 766us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.9552 - val_acc: 0.9029\n",
      "Epoch 88/400\n",
      "1546/1546 [==============================] - 1s 771us/step - loss: 0.0025 - acc: 0.9998 - val_loss: 0.9595 - val_acc: 0.9049\n",
      "Epoch 89/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.9486 - val_acc: 0.9044\n",
      "Epoch 90/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.9509 - val_acc: 0.9052\n",
      "Epoch 91/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.9678 - val_acc: 0.9057\n",
      "Epoch 92/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.9608 - val_acc: 0.9055\n",
      "Epoch 93/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.9602 - val_acc: 0.9055\n",
      "Epoch 94/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.9769 - val_acc: 0.9042\n",
      "Epoch 95/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.9649 - val_acc: 0.9039\n",
      "Epoch 96/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.9690 - val_acc: 0.9065\n",
      "Epoch 97/400\n",
      "1546/1546 [==============================] - 1s 770us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.9665 - val_acc: 0.9058\n",
      "Epoch 98/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.9654 - val_acc: 0.9057\n",
      "Epoch 99/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.9569 - val_acc: 0.9050\n",
      "Epoch 100/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.9644 - val_acc: 0.9039\n",
      "Epoch 101/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.9531 - val_acc: 0.9062\n",
      "Epoch 102/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.9703 - val_acc: 0.9054\n",
      "Epoch 103/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 9.0726e-04 - acc: 0.9999 - val_loss: 0.9626 - val_acc: 0.9041\n",
      "Epoch 104/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 9.9210e-04 - acc: 0.9998 - val_loss: 0.9663 - val_acc: 0.9073\n",
      "Epoch 105/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.9760 - val_acc: 0.9055\n",
      "Epoch 106/400\n",
      "1546/1546 [==============================] - 1s 770us/step - loss: 8.5579e-04 - acc: 0.9998 - val_loss: 0.9739 - val_acc: 0.9070\n",
      "Epoch 107/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.9823 - val_acc: 0.9026\n",
      "Epoch 108/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.9591 - val_acc: 0.9067\n",
      "Epoch 109/400\n",
      "1546/1546 [==============================] - 1s 770us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.9686 - val_acc: 0.9070\n",
      "Epoch 110/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.9724 - val_acc: 0.9060\n",
      "Epoch 111/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 9.2305e-04 - acc: 0.9997 - val_loss: 0.9730 - val_acc: 0.9060\n",
      "Epoch 112/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 5.2026e-04 - acc: 0.9999 - val_loss: 0.9739 - val_acc: 0.9081\n",
      "Epoch 113/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 5.5831e-04 - acc: 0.9998 - val_loss: 0.9724 - val_acc: 0.9075\n",
      "Epoch 114/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 9.4741e-04 - acc: 0.9997 - val_loss: 0.9800 - val_acc: 0.9052\n",
      "Epoch 115/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.9798 - val_acc: 0.9047\n",
      "Epoch 116/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.9688 - val_acc: 0.9047\n",
      "Epoch 117/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.9836 - val_acc: 0.9057\n",
      "Epoch 118/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 6.9265e-04 - acc: 0.9998 - val_loss: 0.9940 - val_acc: 0.9068\n",
      "Epoch 119/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1546/1546 [==============================] - 1s 782us/step - loss: 4.9740e-04 - acc: 0.9999 - val_loss: 0.9945 - val_acc: 0.9052\n",
      "Epoch 120/400\n",
      "1546/1546 [==============================] - 1s 795us/step - loss: 4.1000e-04 - acc: 0.9998 - val_loss: 1.0048 - val_acc: 0.9041\n",
      "Epoch 121/400\n",
      "1546/1546 [==============================] - 1s 801us/step - loss: 8.6512e-04 - acc: 0.9998 - val_loss: 0.9935 - val_acc: 0.9065\n",
      "Epoch 122/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.9762 - val_acc: 0.9055\n",
      "Epoch 123/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.9793 - val_acc: 0.9070\n",
      "Epoch 124/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.9685 - val_acc: 0.9071\n",
      "Epoch 125/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 4.7483e-04 - acc: 0.9998 - val_loss: 0.9802 - val_acc: 0.9073\n",
      "Epoch 126/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 3.4199e-04 - acc: 0.9998 - val_loss: 0.9938 - val_acc: 0.9075\n",
      "Epoch 127/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 3.9385e-04 - acc: 0.9998 - val_loss: 0.9989 - val_acc: 0.9070\n",
      "Epoch 128/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 4.8190e-04 - acc: 0.9998 - val_loss: 0.9917 - val_acc: 0.9058\n",
      "Epoch 129/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.9788 - val_acc: 0.9079\n",
      "Epoch 130/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 8.3141e-04 - acc: 0.9998 - val_loss: 0.9769 - val_acc: 0.9076\n",
      "Epoch 131/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.9847 - val_acc: 0.9078\n",
      "Epoch 132/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 3.4752e-04 - acc: 0.9999 - val_loss: 0.9846 - val_acc: 0.9083\n",
      "Epoch 133/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.9929 - val_acc: 0.9068\n",
      "Epoch 134/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 6.8144e-04 - acc: 0.9997 - val_loss: 0.9825 - val_acc: 0.9079\n",
      "Epoch 135/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.9721 - val_acc: 0.9063\n",
      "Epoch 136/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 3.7981e-04 - acc: 0.9999 - val_loss: 0.9912 - val_acc: 0.9075\n",
      "Epoch 137/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.7319e-04 - acc: 0.9999 - val_loss: 1.0014 - val_acc: 0.9063\n",
      "Epoch 138/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.7073e-04 - acc: 0.9998 - val_loss: 1.0094 - val_acc: 0.9078\n",
      "Epoch 139/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 4.4035e-04 - acc: 0.9998 - val_loss: 1.0087 - val_acc: 0.9039\n",
      "Epoch 140/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 3.2754e-04 - acc: 0.9998 - val_loss: 1.0113 - val_acc: 0.9065\n",
      "Epoch 141/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 7.0213e-04 - acc: 0.9998 - val_loss: 1.0122 - val_acc: 0.9065\n",
      "Epoch 142/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 7.8281e-04 - acc: 0.9998 - val_loss: 1.0140 - val_acc: 0.9067\n",
      "Epoch 143/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 3.1006e-04 - acc: 0.9998 - val_loss: 1.0127 - val_acc: 0.9073\n",
      "Epoch 144/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 2.7263e-04 - acc: 0.9999 - val_loss: 1.0108 - val_acc: 0.9073\n",
      "Epoch 145/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 3.0489e-04 - acc: 0.9998 - val_loss: 1.0211 - val_acc: 0.9071\n",
      "Epoch 146/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.0070 - val_acc: 0.9057\n",
      "Epoch 147/400\n",
      "1546/1546 [==============================] - 1s 793us/step - loss: 5.2527e-04 - acc: 0.9998 - val_loss: 1.0183 - val_acc: 0.9062\n",
      "Epoch 148/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.3947e-04 - acc: 0.9998 - val_loss: 1.0146 - val_acc: 0.9070\n",
      "Epoch 149/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.0028 - val_acc: 0.9060\n",
      "Epoch 150/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 2.9308e-04 - acc: 0.9998 - val_loss: 1.0075 - val_acc: 0.9079\n",
      "Epoch 151/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 7.4868e-04 - acc: 0.9997 - val_loss: 1.0137 - val_acc: 0.9071\n",
      "Epoch 152/400\n",
      "1546/1546 [==============================] - 1s 771us/step - loss: 2.8600e-04 - acc: 0.9998 - val_loss: 1.0156 - val_acc: 0.9071\n",
      "Epoch 153/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 2.4550e-04 - acc: 0.9998 - val_loss: 1.0173 - val_acc: 0.9078\n",
      "Epoch 154/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.0229 - val_acc: 0.9065\n",
      "Epoch 155/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 4.2533e-04 - acc: 0.9997 - val_loss: 1.0045 - val_acc: 0.9070\n",
      "Epoch 156/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 1.0081 - val_acc: 0.9068\n",
      "Epoch 157/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 6.1762e-04 - acc: 0.9997 - val_loss: 1.0100 - val_acc: 0.9067\n",
      "Epoch 158/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 8.0229e-04 - acc: 0.9997 - val_loss: 1.0004 - val_acc: 0.9079\n",
      "Epoch 159/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 4.1067e-04 - acc: 0.9998 - val_loss: 1.0070 - val_acc: 0.9063\n",
      "Epoch 160/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.6430e-04 - acc: 0.9998 - val_loss: 1.0126 - val_acc: 0.9073\n",
      "Epoch 161/400\n",
      "1546/1546 [==============================] - 1s 768us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.0166 - val_acc: 0.9076\n",
      "Epoch 162/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 2.5790e-04 - acc: 0.9999 - val_loss: 1.0201 - val_acc: 0.9068\n",
      "Epoch 163/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 2.8250e-04 - acc: 0.9998 - val_loss: 1.0202 - val_acc: 0.9083\n",
      "Epoch 164/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 2.4052e-04 - acc: 0.9999 - val_loss: 1.0303 - val_acc: 0.9083\n",
      "Epoch 165/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.4228e-04 - acc: 0.9998 - val_loss: 1.0352 - val_acc: 0.9086\n",
      "Epoch 166/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 2.2847e-04 - acc: 0.9998 - val_loss: 1.0457 - val_acc: 0.9067\n",
      "Epoch 167/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 7.1964e-04 - acc: 0.9998 - val_loss: 1.0312 - val_acc: 0.9081\n",
      "Epoch 168/400\n",
      "1546/1546 [==============================] - 1s 811us/step - loss: 9.3759e-04 - acc: 0.9997 - val_loss: 1.0295 - val_acc: 0.9084\n",
      "Epoch 169/400\n",
      "1546/1546 [==============================] - 1s 789us/step - loss: 2.2901e-04 - acc: 0.9998 - val_loss: 1.0327 - val_acc: 0.9091\n",
      "Epoch 170/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 2.2986e-04 - acc: 0.9998 - val_loss: 1.0353 - val_acc: 0.9084\n",
      "Epoch 171/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 8.3962e-04 - acc: 0.9996 - val_loss: 1.0286 - val_acc: 0.9083\n",
      "Epoch 172/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 4.7812e-04 - acc: 0.9997 - val_loss: 1.0240 - val_acc: 0.9084\n",
      "Epoch 173/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 2.4066e-04 - acc: 0.9998 - val_loss: 1.0303 - val_acc: 0.9083\n",
      "Epoch 174/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 8.8664e-04 - acc: 0.9997 - val_loss: 1.0136 - val_acc: 0.9075\n",
      "Epoch 175/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.4350e-04 - acc: 0.9998 - val_loss: 1.0294 - val_acc: 0.9081\n",
      "Epoch 176/400\n",
      "1546/1546 [==============================] - 1s 795us/step - loss: 2.2441e-04 - acc: 0.9998 - val_loss: 1.0378 - val_acc: 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/400\n",
      "1546/1546 [==============================] - 1s 805us/step - loss: 9.4582e-04 - acc: 0.9996 - val_loss: 1.0443 - val_acc: 0.9067\n",
      "Epoch 178/400\n",
      "1546/1546 [==============================] - 1s 794us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 1.0419 - val_acc: 0.9065\n",
      "Epoch 179/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 8.6054e-04 - acc: 0.9997 - val_loss: 1.0408 - val_acc: 0.9060\n",
      "Epoch 180/400\n",
      "1546/1546 [==============================] - 1s 795us/step - loss: 8.6825e-04 - acc: 0.9997 - val_loss: 1.0415 - val_acc: 0.9070\n",
      "Epoch 181/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 0.0011 - acc: 0.9995 - val_loss: 1.0213 - val_acc: 0.9070\n",
      "Epoch 182/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 5.3997e-04 - acc: 0.9998 - val_loss: 1.0143 - val_acc: 0.9081\n",
      "Epoch 183/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 3.4862e-04 - acc: 0.9998 - val_loss: 1.0219 - val_acc: 0.9070\n",
      "Epoch 184/400\n",
      "1546/1546 [==============================] - 1s 800us/step - loss: 2.1576e-04 - acc: 0.9999 - val_loss: 1.0254 - val_acc: 0.9070\n",
      "Epoch 185/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.3106e-04 - acc: 0.9998 - val_loss: 1.0322 - val_acc: 0.9079\n",
      "Epoch 186/400\n",
      "1546/1546 [==============================] - 1s 771us/step - loss: 8.7836e-04 - acc: 0.9997 - val_loss: 1.0152 - val_acc: 0.9088\n",
      "Epoch 187/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.5060e-04 - acc: 0.9998 - val_loss: 1.0377 - val_acc: 0.9073\n",
      "Epoch 188/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 2.3273e-04 - acc: 0.9998 - val_loss: 1.0426 - val_acc: 0.9068\n",
      "Epoch 189/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.2568e-04 - acc: 0.9998 - val_loss: 1.0458 - val_acc: 0.9075\n",
      "Epoch 190/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 2.1964e-04 - acc: 0.9998 - val_loss: 1.0520 - val_acc: 0.9060\n",
      "Epoch 191/400\n",
      "1546/1546 [==============================] - 1s 802us/step - loss: 7.9350e-04 - acc: 0.9997 - val_loss: 1.0422 - val_acc: 0.9067\n",
      "Epoch 192/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.3557e-04 - acc: 0.9998 - val_loss: 1.0393 - val_acc: 0.9070\n",
      "Epoch 193/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.3804e-04 - acc: 0.9998 - val_loss: 1.0433 - val_acc: 0.9068\n",
      "Epoch 194/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 2.0758e-04 - acc: 0.9999 - val_loss: 1.0583 - val_acc: 0.9071\n",
      "Epoch 195/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 4.9121e-04 - acc: 0.9997 - val_loss: 1.0857 - val_acc: 0.9018\n",
      "Epoch 196/400\n",
      "1546/1546 [==============================] - 1s 789us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.0604 - val_acc: 0.9044\n",
      "Epoch 197/400\n",
      "1546/1546 [==============================] - 1s 796us/step - loss: 2.1430e-04 - acc: 0.9998 - val_loss: 1.0615 - val_acc: 0.9055\n",
      "Epoch 198/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.0948e-04 - acc: 0.9998 - val_loss: 1.0632 - val_acc: 0.9062\n",
      "Epoch 199/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.0889e-04 - acc: 0.9998 - val_loss: 1.0639 - val_acc: 0.9071\n",
      "Epoch 200/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.0658e-04 - acc: 0.9999 - val_loss: 1.0655 - val_acc: 0.9079\n",
      "Epoch 201/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 2.1177e-04 - acc: 0.9998 - val_loss: 1.0701 - val_acc: 0.9086\n",
      "Epoch 202/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 2.0754e-04 - acc: 0.9999 - val_loss: 1.0746 - val_acc: 0.9079\n",
      "Epoch 203/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.0455 - val_acc: 0.9060\n",
      "Epoch 204/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.0365 - val_acc: 0.9079\n",
      "Epoch 205/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 2.7558e-04 - acc: 0.9998 - val_loss: 1.0442 - val_acc: 0.9075\n",
      "Epoch 206/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.2757e-04 - acc: 0.9998 - val_loss: 1.0500 - val_acc: 0.9078\n",
      "Epoch 207/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.0479 - val_acc: 0.9062\n",
      "Epoch 208/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 4.8250e-04 - acc: 0.9998 - val_loss: 1.0566 - val_acc: 0.9062\n",
      "Epoch 209/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 3.3298e-04 - acc: 0.9998 - val_loss: 1.0533 - val_acc: 0.9070\n",
      "Epoch 210/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 2.8323e-04 - acc: 0.9998 - val_loss: 1.0621 - val_acc: 0.9062\n",
      "Epoch 211/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 3.8985e-04 - acc: 0.9998 - val_loss: 1.0462 - val_acc: 0.9073\n",
      "Epoch 212/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 2.2085e-04 - acc: 0.9998 - val_loss: 1.0546 - val_acc: 0.9075\n",
      "Epoch 213/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 2.1231e-04 - acc: 0.9998 - val_loss: 1.0628 - val_acc: 0.9073\n",
      "Epoch 214/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 2.2240e-04 - acc: 0.9998 - val_loss: 1.0631 - val_acc: 0.9079\n",
      "Epoch 215/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.1694e-04 - acc: 0.9998 - val_loss: 1.0696 - val_acc: 0.9075\n",
      "Epoch 216/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 2.0936e-04 - acc: 0.9998 - val_loss: 1.0702 - val_acc: 0.9078\n",
      "Epoch 217/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.8416e-04 - acc: 0.9998 - val_loss: 1.0656 - val_acc: 0.9065\n",
      "Epoch 218/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 5.0683e-04 - acc: 0.9998 - val_loss: 1.0593 - val_acc: 0.9070\n",
      "Epoch 219/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.2295e-04 - acc: 0.9998 - val_loss: 1.0570 - val_acc: 0.9073\n",
      "Epoch 220/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 7.2825e-04 - acc: 0.9996 - val_loss: 1.0491 - val_acc: 0.9092\n",
      "Epoch 221/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 4.0441e-04 - acc: 0.9998 - val_loss: 1.0612 - val_acc: 0.9063\n",
      "Epoch 222/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 2.2022e-04 - acc: 0.9998 - val_loss: 1.0582 - val_acc: 0.9078\n",
      "Epoch 223/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.1785e-04 - acc: 0.9998 - val_loss: 1.0645 - val_acc: 0.9086\n",
      "Epoch 224/400\n",
      "1546/1546 [==============================] - 1s 796us/step - loss: 2.1399e-04 - acc: 0.9998 - val_loss: 1.0634 - val_acc: 0.9079\n",
      "Epoch 225/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 1.9974e-04 - acc: 0.9998 - val_loss: 1.0710 - val_acc: 0.9086\n",
      "Epoch 226/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 2.1051e-04 - acc: 0.9998 - val_loss: 1.0772 - val_acc: 0.9084\n",
      "Epoch 227/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 1.9605e-04 - acc: 0.9998 - val_loss: 1.0819 - val_acc: 0.9088\n",
      "Epoch 228/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 1.9853e-04 - acc: 0.9998 - val_loss: 1.0776 - val_acc: 0.9086\n",
      "Epoch 229/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 6.6829e-04 - acc: 0.9996 - val_loss: 1.0849 - val_acc: 0.9067\n",
      "Epoch 230/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 6.0344e-04 - acc: 0.9997 - val_loss: 1.0673 - val_acc: 0.9078\n",
      "Epoch 231/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 5.0383e-04 - acc: 0.9998 - val_loss: 1.0611 - val_acc: 0.9088\n",
      "Epoch 232/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 2.0164e-04 - acc: 0.9998 - val_loss: 1.0683 - val_acc: 0.9081\n",
      "Epoch 233/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 2.2114e-04 - acc: 0.9998 - val_loss: 1.0669 - val_acc: 0.9071\n",
      "Epoch 234/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 1.9354e-04 - acc: 0.9998 - val_loss: 1.0673 - val_acc: 0.9076\n",
      "Epoch 235/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 2.2140e-04 - acc: 0.9999 - val_loss: 1.0693 - val_acc: 0.9083\n",
      "Epoch 236/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 1.8307e-04 - acc: 0.9998 - val_loss: 1.0734 - val_acc: 0.9078\n",
      "Epoch 237/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 2.0158e-04 - acc: 0.9998 - val_loss: 1.0712 - val_acc: 0.9079\n",
      "Epoch 238/400\n",
      "1546/1546 [==============================] - 1s 805us/step - loss: 1.9687e-04 - acc: 0.9998 - val_loss: 1.0769 - val_acc: 0.9076\n",
      "Epoch 239/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.0329e-04 - acc: 0.9998 - val_loss: 1.0786 - val_acc: 0.9091\n",
      "Epoch 240/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 1.8952e-04 - acc: 0.9998 - val_loss: 1.0832 - val_acc: 0.9084\n",
      "Epoch 241/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.0720e-04 - acc: 0.9998 - val_loss: 1.0876 - val_acc: 0.9086\n",
      "Epoch 242/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 6.9575e-04 - acc: 0.9997 - val_loss: 1.0650 - val_acc: 0.9071\n",
      "Epoch 243/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 5.0732e-04 - acc: 0.9998 - val_loss: 1.0674 - val_acc: 0.9086\n",
      "Epoch 244/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 3.4768e-04 - acc: 0.9998 - val_loss: 1.0928 - val_acc: 0.9062\n",
      "Epoch 245/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 4.3828e-04 - acc: 0.9997 - val_loss: 1.0768 - val_acc: 0.9100\n",
      "Epoch 246/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 2.9291e-04 - acc: 0.9999 - val_loss: 1.0641 - val_acc: 0.9094\n",
      "Epoch 247/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 5.0738e-04 - acc: 0.9998 - val_loss: 1.0588 - val_acc: 0.9070\n",
      "Epoch 248/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 4.2143e-04 - acc: 0.9997 - val_loss: 1.0615 - val_acc: 0.9078\n",
      "Epoch 249/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.2947e-04 - acc: 0.9999 - val_loss: 1.0681 - val_acc: 0.9088\n",
      "Epoch 250/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 5.6574e-04 - acc: 0.9998 - val_loss: 1.0648 - val_acc: 0.9065\n",
      "Epoch 251/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 4.0700e-04 - acc: 0.9998 - val_loss: 1.0496 - val_acc: 0.9086\n",
      "Epoch 252/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 8.2788e-04 - acc: 0.9997 - val_loss: 1.0537 - val_acc: 0.9091\n",
      "Epoch 253/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.2720e-04 - acc: 0.9998 - val_loss: 1.0567 - val_acc: 0.9086\n",
      "Epoch 254/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 1.9296e-04 - acc: 0.9999 - val_loss: 1.0573 - val_acc: 0.9081\n",
      "Epoch 255/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 2.0382e-04 - acc: 0.9999 - val_loss: 1.0597 - val_acc: 0.9079\n",
      "Epoch 256/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.1105e-04 - acc: 0.9998 - val_loss: 1.0631 - val_acc: 0.9091\n",
      "Epoch 257/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 7.2043e-04 - acc: 0.9997 - val_loss: 1.0673 - val_acc: 0.9071\n",
      "Epoch 258/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 6.9931e-04 - acc: 0.9997 - val_loss: 1.0554 - val_acc: 0.9065\n",
      "Epoch 259/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 8.0164e-04 - acc: 0.9997 - val_loss: 1.0529 - val_acc: 0.9079\n",
      "Epoch 260/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.2810e-04 - acc: 0.9998 - val_loss: 1.0566 - val_acc: 0.9067\n",
      "Epoch 261/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 5.1839e-04 - acc: 0.9998 - val_loss: 1.0502 - val_acc: 0.9075\n",
      "Epoch 262/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 1.9285e-04 - acc: 0.9999 - val_loss: 1.0512 - val_acc: 0.9089\n",
      "Epoch 263/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 2.1145e-04 - acc: 0.9998 - val_loss: 1.0570 - val_acc: 0.9083\n",
      "Epoch 264/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 1.9222e-04 - acc: 0.9998 - val_loss: 1.0630 - val_acc: 0.9081\n",
      "Epoch 265/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 1.9534e-04 - acc: 0.9999 - val_loss: 1.0679 - val_acc: 0.9081\n",
      "Epoch 266/400\n",
      "1546/1546 [==============================] - 1s 797us/step - loss: 2.5936e-04 - acc: 0.9999 - val_loss: 1.0742 - val_acc: 0.9094\n",
      "Epoch 267/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 9.8638e-04 - acc: 0.9996 - val_loss: 1.0571 - val_acc: 0.9089\n",
      "Epoch 268/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 6.8784e-04 - acc: 0.9998 - val_loss: 1.0642 - val_acc: 0.9091\n",
      "Epoch 269/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 2.1025e-04 - acc: 0.9999 - val_loss: 1.0618 - val_acc: 0.9089\n",
      "Epoch 270/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 2.0818e-04 - acc: 0.9998 - val_loss: 1.0649 - val_acc: 0.9084\n",
      "Epoch 271/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.0587e-04 - acc: 0.9999 - val_loss: 1.0646 - val_acc: 0.9086\n",
      "Epoch 272/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.1330e-04 - acc: 0.9999 - val_loss: 1.0542 - val_acc: 0.9078\n",
      "Epoch 273/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 8.8771e-04 - acc: 0.9995 - val_loss: 1.0539 - val_acc: 0.9100\n",
      "Epoch 274/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 6.0021e-04 - acc: 0.9997 - val_loss: 1.0413 - val_acc: 0.9097\n",
      "Epoch 275/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 3.4560e-04 - acc: 0.9999 - val_loss: 1.0455 - val_acc: 0.9094\n",
      "Epoch 276/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 2.2071e-04 - acc: 0.9999 - val_loss: 1.0327 - val_acc: 0.9089\n",
      "Epoch 277/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 3.0686e-04 - acc: 0.9999 - val_loss: 1.0385 - val_acc: 0.9088\n",
      "Epoch 278/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 2.1918e-04 - acc: 0.9998 - val_loss: 1.0482 - val_acc: 0.9084\n",
      "Epoch 279/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 1.9484e-04 - acc: 0.9999 - val_loss: 1.0537 - val_acc: 0.9091\n",
      "Epoch 280/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 1.9943e-04 - acc: 0.9998 - val_loss: 1.0633 - val_acc: 0.9075\n",
      "Epoch 281/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 8.9252e-04 - acc: 0.9996 - val_loss: 1.0605 - val_acc: 0.9088\n",
      "Epoch 282/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.4280e-04 - acc: 0.9999 - val_loss: 1.0577 - val_acc: 0.9088\n",
      "Epoch 283/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 2.0839e-04 - acc: 0.9998 - val_loss: 1.0604 - val_acc: 0.9088\n",
      "Epoch 284/400\n",
      "1546/1546 [==============================] - 1s 789us/step - loss: 2.0639e-04 - acc: 0.9998 - val_loss: 1.0635 - val_acc: 0.9084\n",
      "Epoch 285/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 1.9699e-04 - acc: 0.9998 - val_loss: 1.0670 - val_acc: 0.9083\n",
      "Epoch 286/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 1.9792e-04 - acc: 0.9998 - val_loss: 1.0752 - val_acc: 0.9078\n",
      "Epoch 287/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 1.8879e-04 - acc: 0.9999 - val_loss: 1.0654 - val_acc: 0.9083\n",
      "Epoch 288/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 1.0573 - val_acc: 0.9097\n",
      "Epoch 289/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 2.2245e-04 - acc: 0.9998 - val_loss: 1.0590 - val_acc: 0.9092\n",
      "Epoch 290/400\n",
      "1546/1546 [==============================] - 1s 793us/step - loss: 1.9492e-04 - acc: 0.9998 - val_loss: 1.0618 - val_acc: 0.9092\n",
      "Epoch 291/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1546/1546 [==============================] - 1s 789us/step - loss: 1.9726e-04 - acc: 0.9998 - val_loss: 1.0731 - val_acc: 0.9083\n",
      "Epoch 292/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 3.3947e-04 - acc: 0.9998 - val_loss: 1.0720 - val_acc: 0.9071\n",
      "Epoch 293/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 4.7126e-04 - acc: 0.9997 - val_loss: 1.0692 - val_acc: 0.9081\n",
      "Epoch 294/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 6.9729e-04 - acc: 0.9997 - val_loss: 1.0654 - val_acc: 0.9078\n",
      "Epoch 295/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 7.4084e-04 - acc: 0.9997 - val_loss: 1.0613 - val_acc: 0.9070\n",
      "Epoch 296/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 4.5450e-04 - acc: 0.9998 - val_loss: 1.0599 - val_acc: 0.9073\n",
      "Epoch 297/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.0365e-04 - acc: 0.9998 - val_loss: 1.0575 - val_acc: 0.9086\n",
      "Epoch 298/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.0867e-04 - acc: 0.9998 - val_loss: 1.0594 - val_acc: 0.9088\n",
      "Epoch 299/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.7363e-04 - acc: 0.9997 - val_loss: 1.0629 - val_acc: 0.9088\n",
      "Epoch 300/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 6.2677e-04 - acc: 0.9996 - val_loss: 1.0590 - val_acc: 0.9075\n",
      "Epoch 301/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 1.9642e-04 - acc: 0.9999 - val_loss: 1.0591 - val_acc: 0.9083\n",
      "Epoch 302/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.1568e-04 - acc: 0.9998 - val_loss: 1.0634 - val_acc: 0.9091\n",
      "Epoch 303/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.0772e-04 - acc: 0.9998 - val_loss: 1.0642 - val_acc: 0.9089\n",
      "Epoch 304/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 2.0176e-04 - acc: 0.9998 - val_loss: 1.0668 - val_acc: 0.9094\n",
      "Epoch 305/400\n",
      "1546/1546 [==============================] - 1s 797us/step - loss: 2.0505e-04 - acc: 0.9999 - val_loss: 1.0703 - val_acc: 0.9089\n",
      "Epoch 306/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 1.8442e-04 - acc: 0.9999 - val_loss: 1.0777 - val_acc: 0.9086\n",
      "Epoch 307/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 4.3491e-04 - acc: 0.9998 - val_loss: 1.0703 - val_acc: 0.9081\n",
      "Epoch 308/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 1.0671 - val_acc: 0.9078\n",
      "Epoch 309/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.1972e-04 - acc: 0.9998 - val_loss: 1.0567 - val_acc: 0.9092\n",
      "Epoch 310/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 7.0409e-04 - acc: 0.9997 - val_loss: 1.0715 - val_acc: 0.9073\n",
      "Epoch 311/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.0782 - val_acc: 0.9058\n",
      "Epoch 312/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 3.9562e-04 - acc: 0.9998 - val_loss: 1.0733 - val_acc: 0.9075\n",
      "Epoch 313/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 3.9648e-04 - acc: 0.9998 - val_loss: 1.0805 - val_acc: 0.9065\n",
      "Epoch 314/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 7.7065e-04 - acc: 0.9997 - val_loss: 1.0468 - val_acc: 0.9065\n",
      "Epoch 315/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.7704e-04 - acc: 0.9999 - val_loss: 1.0522 - val_acc: 0.9070\n",
      "Epoch 316/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.0047e-04 - acc: 0.9999 - val_loss: 1.0561 - val_acc: 0.9073\n",
      "Epoch 317/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 2.0378e-04 - acc: 0.9998 - val_loss: 1.0584 - val_acc: 0.9076\n",
      "Epoch 318/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.0673e-04 - acc: 0.9999 - val_loss: 1.0657 - val_acc: 0.9079\n",
      "Epoch 319/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 1.9771e-04 - acc: 0.9998 - val_loss: 1.0749 - val_acc: 0.9073\n",
      "Epoch 320/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.1235e-04 - acc: 0.9998 - val_loss: 1.0858 - val_acc: 0.9079\n",
      "Epoch 321/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.4175e-04 - acc: 0.9998 - val_loss: 1.1069 - val_acc: 0.9067\n",
      "Epoch 322/400\n",
      "1546/1546 [==============================] - 1s 794us/step - loss: 8.8548e-04 - acc: 0.9996 - val_loss: 1.0765 - val_acc: 0.9070\n",
      "Epoch 323/400\n",
      "1546/1546 [==============================] - 1s 796us/step - loss: 2.2160e-04 - acc: 0.9999 - val_loss: 1.0780 - val_acc: 0.9097\n",
      "Epoch 324/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 2.0565e-04 - acc: 0.9998 - val_loss: 1.0801 - val_acc: 0.9089\n",
      "Epoch 325/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 2.0276e-04 - acc: 0.9998 - val_loss: 1.0783 - val_acc: 0.9089\n",
      "Epoch 326/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.0500e-04 - acc: 0.9998 - val_loss: 1.0785 - val_acc: 0.9081\n",
      "Epoch 327/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 1.9996e-04 - acc: 0.9998 - val_loss: 1.0784 - val_acc: 0.9083\n",
      "Epoch 328/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 1.9531e-04 - acc: 0.9999 - val_loss: 1.0881 - val_acc: 0.9088\n",
      "Epoch 329/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.0755 - val_acc: 0.9081\n",
      "Epoch 330/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 6.5196e-04 - acc: 0.9998 - val_loss: 1.0723 - val_acc: 0.9073\n",
      "Epoch 331/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 2.1679e-04 - acc: 0.9998 - val_loss: 1.0715 - val_acc: 0.9081\n",
      "Epoch 332/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.5514e-04 - acc: 0.9998 - val_loss: 1.0757 - val_acc: 0.9062\n",
      "Epoch 333/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.0218e-04 - acc: 0.9998 - val_loss: 1.0771 - val_acc: 0.9060\n",
      "Epoch 334/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 2.0411e-04 - acc: 0.9998 - val_loss: 1.0771 - val_acc: 0.9062\n",
      "Epoch 335/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 1.9952e-04 - acc: 0.9998 - val_loss: 1.0834 - val_acc: 0.9065\n",
      "Epoch 336/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 1.9197e-04 - acc: 0.9998 - val_loss: 1.0863 - val_acc: 0.9073\n",
      "Epoch 337/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.1446e-04 - acc: 0.9999 - val_loss: 1.0844 - val_acc: 0.9086\n",
      "Epoch 338/400\n",
      "1546/1546 [==============================] - 1s 788us/step - loss: 0.0010 - acc: 0.9996 - val_loss: 1.0840 - val_acc: 0.9062\n",
      "Epoch 339/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 2.0364e-04 - acc: 0.9999 - val_loss: 1.0839 - val_acc: 0.9054\n",
      "Epoch 340/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 5.9389e-04 - acc: 0.9996 - val_loss: 1.0720 - val_acc: 0.9060\n",
      "Epoch 341/400\n",
      "1546/1546 [==============================] - 1s 777us/step - loss: 2.2159e-04 - acc: 0.9999 - val_loss: 1.0761 - val_acc: 0.9068\n",
      "Epoch 342/400\n",
      "1546/1546 [==============================] - 1s 772us/step - loss: 4.1324e-04 - acc: 0.9998 - val_loss: 1.0787 - val_acc: 0.9083\n",
      "Epoch 343/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.5395e-04 - acc: 0.9998 - val_loss: 1.0807 - val_acc: 0.9079\n",
      "Epoch 344/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 4.2408e-04 - acc: 0.9997 - val_loss: 1.0819 - val_acc: 0.9058\n",
      "Epoch 345/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.1477e-04 - acc: 0.9998 - val_loss: 1.0816 - val_acc: 0.9068\n",
      "Epoch 346/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.0647e-04 - acc: 0.9998 - val_loss: 1.0889 - val_acc: 0.9063\n",
      "Epoch 347/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 2.0296e-04 - acc: 0.9998 - val_loss: 1.0862 - val_acc: 0.9071\n",
      "Epoch 348/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 1.9612e-04 - acc: 0.9998 - val_loss: 1.0916 - val_acc: 0.9065\n",
      "Epoch 349/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 9.6301e-04 - acc: 0.9997 - val_loss: 1.0661 - val_acc: 0.9094\n",
      "Epoch 350/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 6.6738e-04 - acc: 0.9998 - val_loss: 1.0611 - val_acc: 0.9083\n",
      "Epoch 351/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.1933e-04 - acc: 0.9998 - val_loss: 1.0729 - val_acc: 0.9062\n",
      "Epoch 352/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 5.0851e-04 - acc: 0.9997 - val_loss: 1.0630 - val_acc: 0.9070\n",
      "Epoch 353/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 2.2548e-04 - acc: 0.9998 - val_loss: 1.0633 - val_acc: 0.9063\n",
      "Epoch 354/400\n",
      "1546/1546 [==============================] - 1s 785us/step - loss: 3.5279e-04 - acc: 0.9997 - val_loss: 1.0625 - val_acc: 0.9076\n",
      "Epoch 355/400\n",
      "1546/1546 [==============================] - 1s 780us/step - loss: 3.0721e-04 - acc: 0.9998 - val_loss: 1.0714 - val_acc: 0.9068\n",
      "Epoch 356/400\n",
      "1546/1546 [==============================] - 1s 797us/step - loss: 2.0669e-04 - acc: 0.9998 - val_loss: 1.0803 - val_acc: 0.9070\n",
      "Epoch 357/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.0644 - val_acc: 0.9075\n",
      "Epoch 358/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 3.3259e-04 - acc: 0.9998 - val_loss: 1.0700 - val_acc: 0.9050\n",
      "Epoch 359/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 2.0084e-04 - acc: 0.9998 - val_loss: 1.0735 - val_acc: 0.9050\n",
      "Epoch 360/400\n",
      "1546/1546 [==============================] - 1s 778us/step - loss: 3.2197e-04 - acc: 0.9998 - val_loss: 1.0753 - val_acc: 0.9057\n",
      "Epoch 361/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 2.0842e-04 - acc: 0.9998 - val_loss: 1.0776 - val_acc: 0.9065\n",
      "Epoch 362/400\n",
      "1546/1546 [==============================] - 1s 793us/step - loss: 2.0666e-04 - acc: 0.9999 - val_loss: 1.0823 - val_acc: 0.9062\n",
      "Epoch 363/400\n",
      "1546/1546 [==============================] - 1s 790us/step - loss: 2.0004e-04 - acc: 0.9998 - val_loss: 1.0855 - val_acc: 0.9068\n",
      "Epoch 364/400\n",
      "1546/1546 [==============================] - 1s 791us/step - loss: 1.9049e-04 - acc: 0.9998 - val_loss: 1.0905 - val_acc: 0.9067\n",
      "Epoch 365/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.2310e-04 - acc: 0.9998 - val_loss: 1.0918 - val_acc: 0.9065\n",
      "Epoch 366/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 1.9673e-04 - acc: 0.9998 - val_loss: 1.1001 - val_acc: 0.9063\n",
      "Epoch 367/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.1867e-04 - acc: 0.9999 - val_loss: 1.0898 - val_acc: 0.9076\n",
      "Epoch 368/400\n",
      "1546/1546 [==============================] - 1s 789us/step - loss: 2.8294e-04 - acc: 0.9998 - val_loss: 1.0894 - val_acc: 0.9076\n",
      "Epoch 369/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.0506e-04 - acc: 0.9998 - val_loss: 1.0983 - val_acc: 0.9073\n",
      "Epoch 370/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 1.8290e-04 - acc: 0.9999 - val_loss: 1.0980 - val_acc: 0.9070\n",
      "Epoch 371/400\n",
      "1546/1546 [==============================] - 1s 770us/step - loss: 2.0388e-04 - acc: 0.9998 - val_loss: 1.1021 - val_acc: 0.9067\n",
      "Epoch 372/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.0351e-04 - acc: 0.9998 - val_loss: 1.0952 - val_acc: 0.9079\n",
      "Epoch 373/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.0421e-04 - acc: 0.9998 - val_loss: 1.0946 - val_acc: 0.9075\n",
      "Epoch 374/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 6.5415e-04 - acc: 0.9998 - val_loss: 1.1018 - val_acc: 0.9070\n",
      "Epoch 375/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 2.1782e-04 - acc: 0.9998 - val_loss: 1.0873 - val_acc: 0.9073\n",
      "Epoch 376/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 1.8947e-04 - acc: 0.9999 - val_loss: 1.0851 - val_acc: 0.9073\n",
      "Epoch 377/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 9.8568e-04 - acc: 0.9997 - val_loss: 1.0757 - val_acc: 0.9081\n",
      "Epoch 378/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 5.3874e-04 - acc: 0.9998 - val_loss: 1.0741 - val_acc: 0.9088\n",
      "Epoch 379/400\n",
      "1546/1546 [==============================] - 1s 770us/step - loss: 2.3450e-04 - acc: 0.9998 - val_loss: 1.0755 - val_acc: 0.9079\n",
      "Epoch 380/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 2.0837e-04 - acc: 0.9998 - val_loss: 1.0739 - val_acc: 0.9086\n",
      "Epoch 381/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 1.9645e-04 - acc: 0.9999 - val_loss: 1.0779 - val_acc: 0.9070\n",
      "Epoch 382/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 3.8148e-04 - acc: 0.9998 - val_loss: 1.0728 - val_acc: 0.9076\n",
      "Epoch 383/400\n",
      "1546/1546 [==============================] - 1s 779us/step - loss: 2.5667e-04 - acc: 0.9999 - val_loss: 1.0741 - val_acc: 0.9079\n",
      "Epoch 384/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 1.9940e-04 - acc: 0.9998 - val_loss: 1.0790 - val_acc: 0.9068\n",
      "Epoch 385/400\n",
      "1546/1546 [==============================] - 1s 769us/step - loss: 2.0321e-04 - acc: 0.9998 - val_loss: 1.0825 - val_acc: 0.9078\n",
      "Epoch 386/400\n",
      "1546/1546 [==============================] - 1s 776us/step - loss: 1.9805e-04 - acc: 0.9998 - val_loss: 1.0874 - val_acc: 0.9088\n",
      "Epoch 387/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 1.9356e-04 - acc: 0.9998 - val_loss: 1.0920 - val_acc: 0.9084\n",
      "Epoch 388/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 1.8310e-04 - acc: 0.9999 - val_loss: 1.0975 - val_acc: 0.9078\n",
      "Epoch 389/400\n",
      "1546/1546 [==============================] - 1s 792us/step - loss: 1.9298e-04 - acc: 0.9999 - val_loss: 1.0954 - val_acc: 0.9086\n",
      "Epoch 390/400\n",
      "1546/1546 [==============================] - 1s 781us/step - loss: 1.7793e-04 - acc: 0.9999 - val_loss: 1.1090 - val_acc: 0.9078\n",
      "Epoch 391/400\n",
      "1546/1546 [==============================] - 1s 789us/step - loss: 8.2153e-04 - acc: 0.9997 - val_loss: 1.0988 - val_acc: 0.9091\n",
      "Epoch 392/400\n",
      "1546/1546 [==============================] - 1s 775us/step - loss: 7.7445e-04 - acc: 0.9997 - val_loss: 1.0939 - val_acc: 0.9081\n",
      "Epoch 393/400\n",
      "1546/1546 [==============================] - 1s 782us/step - loss: 6.5166e-04 - acc: 0.9998 - val_loss: 1.0739 - val_acc: 0.9083\n",
      "Epoch 394/400\n",
      "1546/1546 [==============================] - 1s 773us/step - loss: 2.2625e-04 - acc: 0.9998 - val_loss: 1.0752 - val_acc: 0.9084\n",
      "Epoch 395/400\n",
      "1546/1546 [==============================] - 1s 786us/step - loss: 2.0178e-04 - acc: 0.9998 - val_loss: 1.0763 - val_acc: 0.9086\n",
      "Epoch 396/400\n",
      "1546/1546 [==============================] - 1s 774us/step - loss: 2.0023e-04 - acc: 0.9998 - val_loss: 1.0783 - val_acc: 0.9081\n",
      "Epoch 397/400\n",
      "1546/1546 [==============================] - 1s 787us/step - loss: 2.0708e-04 - acc: 0.9998 - val_loss: 1.0775 - val_acc: 0.9081\n",
      "Epoch 398/400\n",
      "1546/1546 [==============================] - 1s 794us/step - loss: 2.0380e-04 - acc: 0.9998 - val_loss: 1.0817 - val_acc: 0.9084\n",
      "Epoch 399/400\n",
      "1546/1546 [==============================] - 1s 784us/step - loss: 2.0891e-04 - acc: 0.9998 - val_loss: 1.0836 - val_acc: 0.9092\n",
      "Epoch 400/400\n",
      "1546/1546 [==============================] - 1s 783us/step - loss: 1.8763e-04 - acc: 0.9998 - val_loss: 1.0937 - val_acc: 0.9081\n"
     ]
    }
   ],
   "source": [
    "train_out = model.fit([features,question_inputs, m_decoder_inputs], m_decoder_targets, batch_size=100, epochs=400, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = train_out.history['acc']\n",
    "val_accuracy = train_out.history['val_acc']\n",
    "loss = train_out.history['loss']\n",
    "val_loss = train_out.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validat1137153748ion accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model([k_image_input,k_question_input], k_encoder_states)\n",
    "decoder_state_input_h = Input(shape=(embed_size,))\n",
    "decoder_state_input_c = Input(shape=(embed_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = k_decoder_lstm(k_decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = k_decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([k_decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(image_features,input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "  \n",
    "    states_value = encoder_model.predict([image_features,input_seq])\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, vocabulary_size))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 1] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx_to_word[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        decoded_sentence +=\" \"\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '2' or\n",
    "           len(decoded_sentence) > PADDING_LEN-1):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, vocabulary_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD PREPROCESSED TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open inputs of test dataset\n",
    "file = open('image_feature_test.pkl', 'rb')\n",
    "features_test = pickle.load(file)\n",
    "file2 = open('test_df_v_final.pkl', 'rb')\n",
    "df_test= pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions=np.array(df_test['Q_Encoded'])\n",
    "test_questions=np.array([np.array(item) for item in test_questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use model to predict the answer\n",
    "predicted_answers_test=[]\n",
    "for seq_index in range(len(df_test)):\n",
    "    input_seq = test_questions[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(features_test[seq_index: seq_index + 1], input_seq)\n",
    "    predicted_answers_test.append(decoded_sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['yes', '<END>', '<NULL>', ''],\n",
       " ['yes', '<END>', '<NULL>', ''],\n",
       " ['yes', '<END>', '<NULL>', ''],\n",
       " ['yes', '<END>', '<NULL>', ''],\n",
       " ['one', '<END>', '<NULL>', '']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answers_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answers_test=[item[0:len(item)-1] for item in predicted_answers_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to remove end tokens from the predicted answers\n",
    "def find_end(item,st):\n",
    "    for i in range(0,len(item)):\n",
    "        if item[i]==st:\n",
    "            return i\n",
    "    return i+1  \n",
    "predicted_answers_test=[item[0:find_end(item,'<END>')] for item in predicted_answers_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual/target answers\n",
    "test_answers=np.array(df_test['A_parsed'])\n",
    "test_answers=[item for item in test_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029316419746460643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "#Final BLEU Score\n",
    "score = corpus_bleu(test_answers, predicted_answers_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
